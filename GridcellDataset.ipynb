{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_data_object_name(dataset_name, year, month, day, hour, realization, forecast_period):\n",
    "    template_string = \"prods_op_{}_{:02d}{:02d}{:02d}_{:02d}_{:02d}_{:03d}.nc\"\n",
    "    return template_string.format(dataset_name, year, month, day, hour, realization, forecast_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import iris\n",
    "import os\n",
    "import numpy as np\n",
    "import cartopy.crs as ccrs\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "iris.FUTURE.netcdf_promote = True\n",
    "iris.FUTURE.netcdf_no_unlimited = True\n",
    "\n",
    "class UKGridcellDataset():\n",
    "    def __init__(self, filenames, scale_factor, mode='X', altitude_file='surface_altitude.nc', root='../data/'):\n",
    "        filenames.sort()\n",
    "        self.filenames = filenames\n",
    "        self.scale_factor = scale_factor\n",
    "        self.root = root\n",
    "        self.mode = mode\n",
    "        self.altitude_file = altitude_file\n",
    "        times = [d for f in self.filenames for d in self._expand_date(self._extract_date(f))]\n",
    "        self.times = [t for t in times if self._get_filename(t)[0] in self.filenames]\n",
    "        self.n_times = len(self.times)\n",
    "        \n",
    "        self.params = [{'name': 'air_temperature', 'stash': 'm01s03i236'},\n",
    "                       {'name': 'surface_air_pressure', 'stash': 'm01s00i409'},\n",
    "                       {'name': 'x_wind', 'stash': 'm01s03i225'},\n",
    "                       {'name': 'y_wind', 'stash': 'm01s03i226'},\n",
    "                       {'name': 'specific_humidity', 'stash': 'm01s03i237'}]\n",
    "        \n",
    "        c = iris.load(root+paths[0])[0]\n",
    "        self.n_lats = c.coord('grid_latitude').shape[0]\n",
    "        self.n_lons = c.coord('grid_longitude').shape[0]\n",
    "\n",
    "    def _expand_date(self, d):\n",
    "        hs = [i for i in range(1, 4)]\n",
    "        if d.hour == 3:\n",
    "            hs.append(0)\n",
    "        return [d - timedelta(hours=h) for h in hs]\n",
    "\n",
    "    def _extract_date(self, filename):\n",
    "        t = datetime.strptime(filename[:31], 'prods_op_mogreps-uk_%Y%m%d_%H')\n",
    "        lead_time = timedelta(hours=int(filename[-6:-3]))\n",
    "        return t + lead_time\n",
    "    \n",
    "    def _reduce_dim(self, cube, dim):\n",
    "        new_dim = np.linspace(cube.coord(dim).points[0], \n",
    "                              cube.coord(dim).points[-1],\n",
    "                              num = cube.coord(dim).points.shape[0] // self.scale_factor)\n",
    "        return new_dim\n",
    "    \n",
    "    def _upscale(self, cube):\n",
    "        new = cube.copy()\n",
    "        new_lat = self._reduce_dim(cube, 'grid_latitude')\n",
    "        new_lon = self._reduce_dim(cube, 'grid_longitude')\n",
    "        return new.interpolate(sample_points=[('grid_latitude', new_lat), ('grid_longitude', new_lon)],\n",
    "                               scheme=iris.analysis.Linear())\n",
    "    \n",
    "    def _bilinear_downscale(self, upscaled, target):\n",
    "        return upscaled.regrid(target, iris.analysis.Linear()) # defaults to n-linear\n",
    "\n",
    "    def _get_filename(self, time):\n",
    "        run = time\n",
    "        while run.hour not in [3, 9, 15, 21]:\n",
    "            run -= timedelta(hours=1)\n",
    "            \n",
    "        lead = time - run\n",
    "        leadh = int(lead.total_seconds() / 3600)\n",
    "        d_string = datetime.strftime(run, 'prods_op_mogreps-uk_%Y%m%d')\n",
    "        fname = d_string + \"_{:02d}_00_{:03d}.nc\".format(run.hour, ((leadh // 3) + 1) * 3)\n",
    "        \n",
    "        return (fname, leadh % 3)\n",
    "    \n",
    "    def _nearest_dry_cell(self, rain, lat, lon):\n",
    "        ospts = ccrs.OSGB().transform_points(rain.coord_system().as_cartopy_crs(),\n",
    "                                             rain.coord('grid_longitude').points[np.where(rain.data == 0)[1]],\n",
    "                                             rain.coord('grid_latitude').points[np.where(rain.data == 0)[0]])[:,:2]\n",
    "        \n",
    "        nbrs = NearestNeighbors(n_neighbors=1, algorithm='kd_tree').fit(ospts)\n",
    "        \n",
    "        x = ccrs.OSGB().transform_point(rain.coord('grid_longitude').points[lon],\n",
    "                                rain.coord('grid_latitude').points[lat],\n",
    "                                rain.coord_system().as_cartopy_crs())\n",
    "        \n",
    "        return nbrs.kneighbors(np.array([x]))[0].flatten()[0] / 1000\n",
    "    \n",
    "    def _select(self, c, **kwargs):\n",
    "        s = [slice(None, None, None) for _ in range(c.ndim)]\n",
    "        coords = [dc.standard_name for dc in c.dim_coords]\n",
    "        for key, value in kwargs.items():\n",
    "            s[c.coord_dims(key)[0]] = value\n",
    "        return c[tuple(s)]\n",
    "        \n",
    "    def _load_cell(self, time, lat, lon):\n",
    "        result = {}\n",
    "        filename, leadtime = self._get_filename(self.times[time])\n",
    "        cubes = iris.load(self.root + filename, \n",
    "                          iris.AttributeConstraint(STASH=[p['stash'] for p in self.params]))\n",
    "\n",
    "        crs = cubes[0].coords('grid_latitude')[0].coord_system.as_cartopy_crs()\n",
    "        p_lat = cubes[0].coord('grid_latitude')[lat].points\n",
    "        p_lon = cubes[0].coord('grid_longitude')[lon].points\n",
    "        r_lon, r_lat = ccrs.PlateCarree().transform_point(p_lon, p_lat, crs)\n",
    "        result['longitude'] = r_lon; result['latitude'] = r_lat;\n",
    "        \n",
    "        result['DOY'] = self.times[time].timetuple().tm_yday\n",
    "        alt = iris.load(self.root + self.altitude_file)[0]\n",
    "        result['surface_altitude'] = self._select(alt, grid_latitude=lat, grid_longitude=lon).data.item()\n",
    "        \n",
    "        for p in self.params:\n",
    "            c_orig = cubes.extract(iris.AttributeConstraint(STASH=p['stash']))[0]\n",
    "            c = self._bilinear_downscale(self._upscale(c_orig), target=c_orig)\n",
    "            result[p['name']] = self._select(c, grid_latitude=lat, grid_longitude=lon, time=leadtime).data.item()\n",
    "        \n",
    "        p = {'name': 'stratiform_rainfall_amount', 'stash': 'm01s04i201'}\n",
    "        c_orig = cubes.extract(iris.AttributeConstraint(STASH=p['stash']))[0]\n",
    "        c = self._bilinear_downscale(self._upscale(c_orig), target=c_orig)\n",
    "        result[p['name']] = self._select(c, grid_latitude=lat, grid_longitude=lon, time=leadtime).data.item()\n",
    "        result[p['name'] + '_up'] = self._select(c, grid_latitude=lat+1, grid_longitude=lon, time=leadtime).data.item()\n",
    "        result[p['name'] + '_down'] = self._select(c, grid_latitude=lat-1, grid_longitude=lon, time=leadtime).data.item()\n",
    "        result[p['name'] + '_left'] = self._select(c, grid_latitude=lat, grid_longitude=lon-1, time=leadtime).data.item()\n",
    "        result[p['name'] + '_right'] = self._select(c, grid_latitude=lat, grid_longitude=lon+1, time=leadtime).data.item()\n",
    "        \n",
    "        empty = slice(None, None, None)\n",
    "        rain = self._select(c, grid_latitude=empty, grid_longitude=empty, time=leadtime)\n",
    "        result['distance'] = self._nearest_dry_cell(rain, lat, lon)\n",
    "        \n",
    "#         return result\n",
    "        target = self._select(c_orig, grid_latitude=lat, grid_longitude=lon, time=leadtime).data.item()\n",
    "    \n",
    "        if self.mode == 'X':\n",
    "            return np.array([v for k, v in result.items()])\n",
    "        else:\n",
    "            return np.array([target])\n",
    "        \n",
    "    def _convert_id(self, idx):\n",
    "        time = idx // ((self.n_lats - 2) * (self.n_lons - 2))\n",
    "        r = idx % ((self.n_lats - 2) * (self.n_lons - 2))\n",
    "        lat = r // (self.n_lons - 2)\n",
    "        lon = r % (self.n_lons - 2)\n",
    "        return (time, lat + 1, lon + 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.n_times * (self.n_lats - 2) * (self.n_lons - 2)) - 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if isinstance(idx, slice):\n",
    "            return np.array([self.__getitem__(x) for x in range(*idx.indices(self.__len__()))])\n",
    "        return self._load_cell(*self._convert_id(idx))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '../data/'\n",
    "paths = [f for f in os.listdir(path) if f[:5] == 'prods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# iris.load([path + p for p in paths])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = [{'name': 'air_temperature', 'stash': 'm01s03i236'},\n",
    "          {'name': 'surface_air_pressure', 'stash': 'm01s00i409'},\n",
    "          {'name': 'x_wind', 'stash': 'm01s03i225'},\n",
    "          {'name': 'y_wind', 'stash': 'm01s03i226'},\n",
    "          {'name': 'specific_humidity', 'stash': 'm01s03i237'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dataset = UKGridcellDataset(paths, scale_factor=1)\n",
    "dataset2 = UKGridcellDataset(paths, scale_factor=2)\n",
    "dataset2y = UKGridcellDataset(paths, scale_factor=2, mode='y')\n",
    "# dataset4 = UKGridcellDataset(paths, scale_factor=4)\n",
    "# dataset8 = UKGridcellDataset(paths, scale_factor=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = list(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pprint\n",
    "# i = np.random.randint(len(dataset))\n",
    "# pprint.pprint(dataset[i], width=1)\n",
    "# pprint.pprint(dataset2[i], width=1)\n",
    "# pprint.pprint(dataset4[i], width=1)\n",
    "# pprint.pprint(dataset8[i], width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for i in [1,2,4,8]:\n",
    "#     plt.pcolormesh(_bilinear_downscale(_upscale(rain, i), rain).data)\n",
    "#     plt.colorbar()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=20, max_features='sqrt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = dataset2[:100][:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y = dataset2[:100][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "rf.fit(dataset2, dataset2y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt = dataset2[100:200][:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yt = dataset2[100:200][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(Xt, yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf.score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
